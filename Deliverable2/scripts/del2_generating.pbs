#!/bin/bash
# Job name
#PBS -N del2_generating
# Output files
#PBS -o ./results/del2_g.out
#PBS -e ./results/del2_g.err
# Queue name
#PBS -q short_cpuQ
# Set the maximum wall time
#PBS -l walltime=0:05:00
# Number of nodes, cpus, mpi processors and amount of memory
#PBS -l select=4:ncpus=12:mpiprocs=12:mem=8gb


# Test on generated matrixes with 9% sparsity, doubling both size and number of processes

# To store data in a compact and plottable way
RESULT_FILE="results/to_plot/del2_g.txt"


# Modules for python and MPI
module load gcc91
module load mpich-3.2.1--gcc-9.1.0


# Select the working directory 
#cd Deliverable2
cd "$PBS_O_WORKDIR"

echo "Working directory: $(pwd)"

# Compile the code
mpicc ./src/execute_mpi_generating.c -o del2
#mpicxx code_mpi.cpp -o code.out

# Remove previous results
if [ -f "$RESULT_FILE" ]; then
    rm "$RESULT_FILE"
fi


# Run the code
# Since we're working on strong scaling, we double at each iteration the number of processes

# For each run, do 10 iterations
# The number of processes is (process 0 + working processes)
# mpirun -np "NUM_PROCESSES" "exectuable" "MATRIX_FILE" "iterations" "RESULT_FILE"
echo "=-=-=-=-=-=-=-=-=-="
echo "Running with 2 processes"
mpirun -np 3 ./del2 10 "$RESULT_FILE" 8 8
echo "=-=-=-=-=-=-=-=-=-="


rm ./del2
echo ""
echo "=-=-=-=-=-=-=-=-=-="
echo "Execution completed"
